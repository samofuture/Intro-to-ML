{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #5\n",
    "---\n",
    "Student Name: Sam Crane\n",
    "\n",
    "Student ID: 801101091\n",
    "\n",
    "GitHub: https://github.com/samofuture/Intro-to-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w2, w1, b):\n",
    "    return w2 * t_u ** 2 + w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(t_u, w1, b):\n",
    "    return w1 * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(num_epochs, optimizer, params: torch.Tensor, t_u, t_c, linear: bool = False):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        if not linear:\n",
    "            t_p = model(t_u, *params)\n",
    "        else:\n",
    "            t_p = linear_model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch} Loss: {float(loss)}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] \n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "t_un = (t_u - t_u.min()) / (t_u.max() - t_u.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 2.751105546951294\n",
      "Epoch 1000 Loss: 2.3994340896606445\n",
      "Epoch 1500 Loss: 2.263638734817505\n",
      "Epoch 2000 Loss: 2.168210983276367\n",
      "Epoch 2500 Loss: 2.1171624660491943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000 Loss: 2.0971312522888184\n",
      "Epoch 3500 Loss: 2.091726303100586\n",
      "Epoch 4000 Loss: 2.0908114910125732\n",
      "Epoch 4500 Loss: 2.0907235145568848\n",
      "Epoch 5000 Loss: 2.0907206535339355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10.2264, 22.2948, -3.9061], requires_grad=True)"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.1)\n",
    "best_params = training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 43.87403106689453\n",
      "Epoch 1000 Loss: 23.40558433532715\n",
      "Epoch 1500 Loss: 16.16440773010254\n",
      "Epoch 2000 Loss: 10.451733589172363\n",
      "Epoch 2500 Loss: 6.443504333496094\n",
      "Epoch 3000 Loss: 4.107592582702637\n",
      "Epoch 3500 Loss: 3.0116372108459473\n",
      "Epoch 4000 Loss: 2.6113815307617188\n",
      "Epoch 4500 Loss: 2.4906833171844482\n",
      "Epoch 5000 Loss: 2.4417731761932373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([16.6260, 15.4963, -2.5505], requires_grad=True)"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.01)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 141.23663330078125\n",
      "Epoch 1000 Loss: 122.945556640625\n",
      "Epoch 1500 Loss: 106.80143737792969\n",
      "Epoch 2000 Loss: 92.5957260131836\n",
      "Epoch 2500 Loss: 80.15706634521484\n",
      "Epoch 3000 Loss: 69.34261322021484\n",
      "Epoch 3500 Loss: 60.029788970947266\n",
      "Epoch 4000 Loss: 52.10824203491211\n",
      "Epoch 4500 Loss: 45.47208786010742\n",
      "Epoch 5000 Loss: 40.012351989746094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.4156, 5.3362, 4.0237], requires_grad=True)"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.001)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 159.7061767578125\n",
      "Epoch 1000 Loss: 157.54910278320312\n",
      "Epoch 1500 Loss: 155.41587829589844\n",
      "Epoch 2000 Loss: 153.30519104003906\n",
      "Epoch 2500 Loss: 151.21585083007812\n",
      "Epoch 3000 Loss: 149.14695739746094\n",
      "Epoch 3500 Loss: 147.09756469726562\n",
      "Epoch 4000 Loss: 145.06761169433594\n",
      "Epoch 4500 Loss: 143.05577087402344\n",
      "Epoch 5000 Loss: 141.06312561035156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4953, 1.4948, 0.4935], requires_grad=True)"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.0001)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 2.2482290267944336\n",
      "Epoch 1000 Loss: 2.1626265048980713\n",
      "Epoch 1500 Loss: 2.1235475540161133\n",
      "Epoch 2000 Loss: 2.105706214904785\n",
      "Epoch 2500 Loss: 2.097562074661255\n",
      "Epoch 3000 Loss: 2.093844413757324\n",
      "Epoch 3500 Loss: 2.092146158218384\n",
      "Epoch 4000 Loss: 2.091371774673462\n",
      "Epoch 4500 Loss: 2.091017484664917\n",
      "Epoch 5000 Loss: 2.090855836868286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([10.3515, 22.1651, -3.8814], requires_grad=True)"
      ]
     },
     "execution_count": 804,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.1)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 7.31503438949585\n",
      "Epoch 1000 Loss: 2.9870688915252686\n",
      "Epoch 1500 Loss: 2.436879873275757\n",
      "Epoch 2000 Loss: 2.351578712463379\n",
      "Epoch 2500 Loss: 2.3246498107910156\n",
      "Epoch 3000 Loss: 2.3061230182647705\n",
      "Epoch 3500 Loss: 2.2897753715515137\n",
      "Epoch 4000 Loss: 2.2747533321380615\n",
      "Epoch 4500 Loss: 2.2608797550201416\n",
      "Epoch 5000 Loss: 2.248051404953003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([14.5804, 17.7796, -3.0443], requires_grad=True)"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.01)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 42.169071197509766\n",
      "Epoch 1000 Loss: 29.084794998168945\n",
      "Epoch 1500 Loss: 23.6975154876709\n",
      "Epoch 2000 Loss: 19.651195526123047\n",
      "Epoch 2500 Loss: 16.389543533325195\n",
      "Epoch 3000 Loss: 13.745458602905273\n",
      "Epoch 3500 Loss: 11.601007461547852\n",
      "Epoch 4000 Loss: 9.861629486083984\n",
      "Epoch 4500 Loss: 8.450728416442871\n",
      "Epoch 5000 Loss: 7.306186199188232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([11.9285, 12.2284,  0.9594], requires_grad=True)"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.001)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 132.0695343017578\n",
      "Epoch 1000 Loss: 109.2575454711914\n",
      "Epoch 1500 Loss: 91.80365753173828\n",
      "Epoch 2000 Loss: 78.41097259521484\n",
      "Epoch 2500 Loss: 68.09719848632812\n",
      "Epoch 3000 Loss: 60.11845397949219\n",
      "Epoch 3500 Loss: 53.911415100097656\n",
      "Epoch 4000 Loss: 49.04937744140625\n",
      "Epoch 4500 Loss: 45.209232330322266\n",
      "Epoch 5000 Loss: 42.146183013916016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.3909, 5.2344, 4.7822], requires_grad=True)"
      ]
     },
     "execution_count": 807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.0001)\n",
    "training_loop(5000, optimizer, params=params, t_u=t_un, t_c=t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear vs. Nonlinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 9.509765625\n",
      "Epoch 1000 Loss: 3.051999807357788\n",
      "Epoch 1500 Loss: 2.927941083908081\n",
      "Epoch 2000 Loss: 2.927644968032837\n",
      "Epoch 2500 Loss: 2.9276463985443115\n",
      "Epoch 3000 Loss: 2.9276459217071533\n",
      "Epoch 3500 Loss: 2.9276459217071533\n",
      "Epoch 4000 Loss: 2.9276459217071533\n",
      "Epoch 4500 Loss: 2.927645206451416\n",
      "Epoch 5000 Loss: 2.927645683288574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([32.2600, -5.6031], requires_grad=True)"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([lin_params], 0.1)\n",
    "linear_params = training_loop(5000, optimizer, lin_params, t_u=t_un, t_c=t_c, linear=True)\n",
    "linear_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500 Loss: 19.66142463684082\n",
      "Epoch 1000 Loss: 8.339456558227539\n",
      "Epoch 1500 Loss: 4.677872180938721\n",
      "Epoch 2000 Loss: 3.4936881065368652\n",
      "Epoch 2500 Loss: 3.110708475112915\n",
      "Epoch 3000 Loss: 2.986849308013916\n",
      "Epoch 3500 Loss: 2.9467933177948\n",
      "Epoch 4000 Loss: 2.9338371753692627\n",
      "Epoch 4500 Loss: 2.929647922515869\n",
      "Epoch 5000 Loss: 2.9282941818237305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([32.1654, -5.5531], requires_grad=True)"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([lin_params], 0.01)\n",
    "training_loop(5000, optimizer, lin_params, t_u=t_un, t_c=t_c, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_vals = np.linspace(t_un.min(), t_un.max(), 1000)\n",
    "\n",
    "linear_predictions = linear_model(x_vals, float(linear_params[0]), float(linear_params[1]))\n",
    "nonlinear_predictions = model(x_vals, float(best_params[0]), float(best_params[1]), float(best_params[2]))\n",
    "\n",
    "# Assuming x_vals is adjusted for normalization\n",
    "plt.plot(x_vals, linear_predictions, label='Linear Predictions')\n",
    "plt.plot(x_vals, nonlinear_predictions, label='Nonlinear Predictions')\n",
    "plt.scatter(t_un, t_c, label='Actual Data', color='red')\n",
    "\n",
    "# Add titles and legends\n",
    "plt.title('Temperature Predictions vs. Actual Data')\n",
    "plt.xlabel('X Values (Normalized)')\n",
    "plt.ylabel('Y Values')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models above have the following (best case) losses:\n",
    "- Nonlinear (ADAM): 2.0907\n",
    "- Nonlinear (SGD): 2.0908\n",
    "- Linear (ADAM): 2.9276\n",
    "- Linear (SGD): 2.9283\n",
    "\n",
    "This shows numerically how the nonlinear model fits the data better. The model also visually fits the data better.\n",
    "\n",
    "Comparing the ADAM and the SGD optimizers, the SGD looks like it handles a larger learning rate better than a smaller one like ADAM, but performs a little worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(t_in, weights, bias):\n",
    "    return torch.matmul(t_in, weights.double()) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(num_epochs, optimizer, params: torch.Tensor, t_in, t_out, v_in, v_out):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        t_p = linear_model(t_in, params[:-1], params[-1])\n",
    "        train_loss = loss_fn(t_p, t_out)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            v_p = linear_model(v_in, params[:-1], params[-1])\n",
    "            valid_loss = loss_fn(v_p, v_out)\n",
    "            print(f\"Epoch {epoch}:\")\n",
    "            print(f\"\\tTraining Loss: {float(train_loss)}\")\n",
    "            print(f\"\\tValidation Loss: {float(valid_loss)}\")\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data() -> pd.DataFrame:\n",
    "    df = pd.read_csv(\"Housing.csv\")\n",
    "\n",
    "    df['mainroad'] = df['mainroad'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    df['guestroom'] = df['guestroom'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    df['basement'] = df['basement'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    df['hotwaterheating'] = df['hotwaterheating'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    df['airconditioning'] = df['airconditioning'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    df['prefarea'] = df['prefarea'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "    df['furnishingstatus'] = df['furnishingstatus'].apply(lambda x: 2 if x == 'furnished' else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedrooms  bathrooms  stories  parking\n",
       "0  7420         4          2        3        2\n",
       "1  8960         4          4        4        3\n",
       "2  9960         3          2        2        2\n",
       "3  7500         4          2        2        3\n",
       "4  7420         4          1        2        2"
      ]
     },
     "execution_count": 814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = prep_data()\n",
    "# area, bedrooms, bathrooms, stories, parking\n",
    "price = og_df.pop('price').to_numpy()\n",
    "df = og_df[['area', 'bedrooms', 'bathrooms', 'stories', 'parking']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = StandardScaler()\n",
    "data = scaler_x.fit_transform(df)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, price, test_size=0.2, random_state=15)\n",
    "\n",
    "train_inputs = torch.tensor(X_train)\n",
    "train_outputs = torch.tensor(Y_train)\n",
    "Y_test = torch.tensor(Y_test)\n",
    "X_test = torch.tensor(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922038059221.56\n",
      "\tValidation Loss: 27376514717869.215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000:\n",
      "\tTraining Loss: 25921145965231.312\n",
      "\tValidation Loss: 27375621239662.55\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25920253913132.258\n",
      "\tValidation Loss: 27374727807284.727\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25919361967566.91\n",
      "\tValidation Loss: 27373834485028.105\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25918470114945.273\n",
      "\tValidation Loss: 27372941264065.88\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25917578267681.11\n",
      "\tValidation Loss: 27372048048916.305\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25916686464661.742\n",
      "\tValidation Loss: 27371154882178.035\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25915794713223.87\n",
      "\tValidation Loss: 27370261771682.12\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25914903013367.496\n",
      "\tValidation Loss: 27369368717428.56\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25914011365092.613\n",
      "\tValidation Loss: 27368475719417.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([500.9217, 500.9103, 500.9128, 500.9115, 500.9130, 500.0050],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.1)\n",
    "housing_lin_params = training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)\n",
    "housing_lin_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922839404500.293\n",
      "\tValidation Loss: 27377318918502.09\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 25922750182905.18\n",
      "\tValidation Loss: 27377229557848.98\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25922660961025.285\n",
      "\tValidation Loss: 27377140196988.28\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25922571739669.418\n",
      "\tValidation Loss: 27377050836682.504\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25922482518821.637\n",
      "\tValidation Loss: 27376961476939.42\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25922393298489.918\n",
      "\tValidation Loss: 27376872117759.035\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25922304090443.97\n",
      "\tValidation Loss: 27376782770923.37\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25922214888161.082\n",
      "\tValidation Loss: 27376693429911.55\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25922125686394.06\n",
      "\tValidation Loss: 27376604089462.215\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25922036485142.895\n",
      "\tValidation Loss: 27376514749575.36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([50.9973, 50.9973, 50.9973, 50.9973, 50.9973, 49.9976],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.01)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922919542237.105\n",
      "\tValidation Loss: 27377399342025.26\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 25922910619997.715\n",
      "\tValidation Loss: 27377390405882.32\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25922901697978.598\n",
      "\tValidation Loss: 27377381469942.12\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25922892775965.074\n",
      "\tValidation Loss: 27377372534007.53\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25922883854521.13\n",
      "\tValidation Loss: 27377363598657.535\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25922874933083.477\n",
      "\tValidation Loss: 27377354663313.164\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25922866011650.992\n",
      "\tValidation Loss: 27377345727974.42\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25922857090223.656\n",
      "\tValidation Loss: 27377336792641.305\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25922848168799.22\n",
      "\tValidation Loss: 27377327857311.496\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25922839247382.207\n",
      "\tValidation Loss: 27377318921989.63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.9998, 5.9998, 5.9998, 5.9998, 5.9998, 4.9998], requires_grad=True)"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922919542237.105\n",
      "\tValidation Loss: 27377399342025.26\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 25922910619997.715\n",
      "\tValidation Loss: 27377390405882.32\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25922901697978.598\n",
      "\tValidation Loss: 27377381469942.12\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25922892775965.074\n",
      "\tValidation Loss: 27377372534007.53\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25922883854521.13\n",
      "\tValidation Loss: 27377363598657.535\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25922874933083.477\n",
      "\tValidation Loss: 27377354663313.164\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25922866011650.992\n",
      "\tValidation Loss: 27377345727974.42\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25922857090223.656\n",
      "\tValidation Loss: 27377336792641.305\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25922848168799.22\n",
      "\tValidation Loss: 27377327857311.496\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25922839247382.207\n",
      "\tValidation Loss: 27377318921989.63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.9998, 5.9998, 5.9998, 5.9998, 5.9998, 4.9998], requires_grad=True)"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 1507382604577.2354\n",
      "\tValidation Loss: 1662434492724.132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 766161.7500,  128552.7109,  505373.0938,  518739.1562,  283620.4062,\n",
       "        4740832.0000], requires_grad=True)"
      ]
     },
     "execution_count": 820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.1)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 1507386215444.318\n",
      "\tValidation Loss: 1662248158546.9\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 1507382604776.3484\n",
      "\tValidation Loss: 1662436266422.8076\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 1507382604729.9468\n",
      "\tValidation Loss: 1662436580651.684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 766160.0625,  128554.1406,  505372.1562,  518738.0625,  283621.8125,\n",
       "        4740821.0000], requires_grad=True)"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.01)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 4641716340687.084\n",
      "\tValidation Loss: 5322454411895.079\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 1943805189537.7068\n",
      "\tValidation Loss: 2271569319505.7476\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 1572475413525.521\n",
      "\tValidation Loss: 1780470312898.3574\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 1518214421849.922\n",
      "\tValidation Loss: 1688471739953.9717\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 1509500415948.3904\n",
      "\tValidation Loss: 1668249916813.992\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 1507877293003.6233\n",
      "\tValidation Loss: 1663352000621.6482\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 1507515802958.6023\n",
      "\tValidation Loss: 1662228525386.9253\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 1507421699291.8513\n",
      "\tValidation Loss: 1662078223581.3801\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 1507394613449.1782\n",
      "\tValidation Loss: 1662153069945.7844\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 1507386371617.8171\n",
      "\tValidation Loss: 1662249069560.7776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 765719.5000,  130439.9297,  504659.3125,  517359.2812,  284054.4375,\n",
       "        4740416.5000], requires_grad=True)"
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 21258326769161.105\n",
      "\tValidation Loss: 22626776042540.562\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 17511808227876.092\n",
      "\tValidation Loss: 18799129217945.29\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 14499868528241.479\n",
      "\tValidation Loss: 15703650394132.19\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 12071740582446.129\n",
      "\tValidation Loss: 13192035229698.766\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 10109518632874.418\n",
      "\tValidation Loss: 11148231494982.557\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 8520428771927.033\n",
      "\tValidation Loss: 9480792609376.025\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 7231153460144.087\n",
      "\tValidation Loss: 8117297392306.548\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 6183440535891.59\n",
      "\tValidation Loss: 7000041872257.728\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 5330849624586.3955\n",
      "\tValidation Loss: 6082868943709.304\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 4636188633076.935\n",
      "\tValidation Loss: 5328663224149.18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 541967.8750,  305071.5000,  379193.1875,  342289.7188,  304700.3750,\n",
       "        2993756.2500], requires_grad=True)"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.0001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models above have the following (best case) validation losses:\n",
    "- ADAM: \n",
    "    - 0.1: 27368475719417.35\n",
    "    - 0.01: 27376514749575.36\n",
    "    - 0.001: 27377318921989.63\n",
    "    - 0.0001: 27377318921989.63\n",
    "- SGD:\n",
    "    - 0.1: 1662434492724.132\n",
    "    - 0.01: 1662436580651.684\n",
    "    - 0.001: 1662249069560.7776\n",
    "    - 0.0001: 5328663224149.18\n",
    "\n",
    "In my previous homework the losses were close to about 1.5e13. The ADAM set has a worse loss than the original linear regression, however the SGD set has a significantly better loss of 1.6e12."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>stories</th>\n",
       "      <th>mainroad</th>\n",
       "      <th>guestroom</th>\n",
       "      <th>basement</th>\n",
       "      <th>hotwaterheating</th>\n",
       "      <th>airconditioning</th>\n",
       "      <th>parking</th>\n",
       "      <th>prefarea</th>\n",
       "      <th>furnishingstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8960</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9960</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7420</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  bedrooms  bathrooms  stories  mainroad  guestroom  basement  \\\n",
       "0  7420         4          2        3         1          0         0   \n",
       "1  8960         4          4        4         1          0         0   \n",
       "2  9960         3          2        2         1          0         1   \n",
       "3  7500         4          2        2         1          0         1   \n",
       "4  7420         4          1        2         1          1         1   \n",
       "\n",
       "   hotwaterheating  airconditioning  parking  prefarea  furnishingstatus  \n",
       "0                0                1        2         1                 2  \n",
       "1                0                1        3         0                 2  \n",
       "2                0                0        2         1                 0  \n",
       "3                0                1        3         1                 2  \n",
       "4                0                1        2         0                 2  "
      ]
     },
     "execution_count": 824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_df = prep_data()\n",
    "price = og_df.pop('price').to_numpy()\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "data = scaler_x.fit_transform(og_df)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, price, test_size=0.2, random_state=15)\n",
    "\n",
    "train_inputs = torch.tensor(X_train)\n",
    "train_outputs = torch.tensor(Y_train)\n",
    "Y_test = torch.tensor(Y_test)\n",
    "X_test = torch.tensor(X_test)\n",
    "og_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADAM Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25921731391188.605\n",
      "\tValidation Loss: 27375986125170.15\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 25920538168385.363\n",
      "\tValidation Loss: 27374574605766.4\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25919345110838.19\n",
      "\tValidation Loss: 27373163317829.445\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25918152283883.453\n",
      "\tValidation Loss: 27371752316530.254\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25916959622628.543\n",
      "\tValidation Loss: 27370341519823.57\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25915767029863.344\n",
      "\tValidation Loss: 27368930823996.863\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25914574572377.652\n",
      "\tValidation Loss: 27367520323728.13\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25913382257335.465\n",
      "\tValidation Loss: 27366110006308.21\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25912190098532.78\n",
      "\tValidation Loss: 27364699867796.37\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25910998086953.48\n",
      "\tValidation Loss: 27363289898558.938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([500.9055, 500.9014, 500.8997, 500.9022, 500.8670, 500.5865, 500.7296,\n",
       "        500.8219, 500.9032, 500.8975, 500.8954, 500.8673, 500.0066],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.1)\n",
    "housing_lin_params = training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)\n",
    "housing_lin_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922803308964.93\n",
      "\tValidation Loss: 27377256721000.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000:\n",
      "\tTraining Loss: 25922683958313.18\n",
      "\tValidation Loss: 27377115530995.426\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25922564608382.98\n",
      "\tValidation Loss: 27376974342150.31\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25922445259165.72\n",
      "\tValidation Loss: 27376833155461.29\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25922325911295.426\n",
      "\tValidation Loss: 27376691970372.992\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25922206564785.207\n",
      "\tValidation Loss: 27376550786888.55\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25922087235827.047\n",
      "\tValidation Loss: 27376409622289.65\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25921967914494.715\n",
      "\tValidation Loss: 27376268465605.73\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25921848594521.973\n",
      "\tValidation Loss: 27376127310525.137\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25921729275908.824\n",
      "\tValidation Loss: 27375986157047.863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([50.9973, 50.9973, 50.9973, 50.9973, 50.9971, 50.9934, 50.9963, 50.9969,\n",
       "        50.9973, 50.9972, 50.9972, 50.9970, 49.9976], requires_grad=True)"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.01)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922910508979.84\n",
      "\tValidation Loss: 27377383792113.66\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 25922898573568.91\n",
      "\tValidation Loss: 27377369672526.203\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25922886638745.15\n",
      "\tValidation Loss: 27377355553769.773\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25922874703936.137\n",
      "\tValidation Loss: 27377341435029.38\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25922862769705.156\n",
      "\tValidation Loss: 27377327316883.984\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25922850835488.9\n",
      "\tValidation Loss: 27377313198754.625\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25922838901286.242\n",
      "\tValidation Loss: 27377299080641.305\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25922826967097.184\n",
      "\tValidation Loss: 27377284962544.016\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25922815032919.465\n",
      "\tValidation Loss: 27377270844460.45\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25922803098757.6\n",
      "\tValidation Loss: 27377256726395.24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.9998, 5.9998, 5.9998, 5.9998, 5.9998, 5.9998, 5.9998, 5.9998, 5.9998,\n",
       "        5.9998, 5.9998, 5.9998, 4.9998], requires_grad=True)"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 25922921229316.71\n",
      "\tValidation Loss: 27377396499670.953\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 25922920035673.953\n",
      "\tValidation Loss: 27377395087585.18\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 25922918842031.4\n",
      "\tValidation Loss: 27377393675499.637\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 25922917648388.91\n",
      "\tValidation Loss: 27377392263414.184\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 25922916454746.56\n",
      "\tValidation Loss: 27377390851329.03\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 25922915261175.035\n",
      "\tValidation Loss: 27377389439316.27\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 25922914067603.652\n",
      "\tValidation Loss: 27377388027303.668\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 25922912874032.41\n",
      "\tValidation Loss: 27377386615291.23\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 25922911680461.293\n",
      "\tValidation Loss: 27377385203278.945\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 25922910486890.312\n",
      "\tValidation Loss: 27377383791266.824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.5001, 1.5001, 1.5001, 1.5001, 1.5001, 1.5001, 1.5001, 1.5001, 1.5001,\n",
       "        1.5001, 1.5001, 1.5001, 0.5000], requires_grad=True)"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], 0.0001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 1090467899724.8202\n",
      "\tValidation Loss: 1377610385759.4404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 566222.0625,  112292.5625,  430681.3438,  433103.7812,  170471.9844,\n",
       "          53671.8516,  197902.0625,  183952.2031,  454856.2188,  204145.7344,\n",
       "         271416.5938,   79551.2578, 4755640.5000], requires_grad=True)"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.1)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.01 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 1090479734892.7542\n",
      "\tValidation Loss: 1376975953311.8682\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 1090467902857.2993\n",
      "\tValidation Loss: 1377594844195.945\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 1090467899886.6433\n",
      "\tValidation Loss: 1377610918904.6133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 566219.8125,  112293.8203,  430682.2812,  433101.5000,  170472.7812,\n",
       "          53671.8633,  197900.5781,  183952.9375,  454857.5000,  204146.0938,\n",
       "         271417.5938,   79551.3047, 4755629.0000], requires_grad=True)"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.01)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 4222745994444.868\n",
      "\tValidation Loss: 4870651697414.323\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 1529634151516.2778\n",
      "\tValidation Loss: 1927493941369.3716\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 1156077887251.0\n",
      "\tValidation Loss: 1474907239802.5115\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 1101447805415.0837\n",
      "\tValidation Loss: 1396886639064.551\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 1092701028757.6425\n",
      "\tValidation Loss: 1381184328787.9885\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 1091051569037.6569\n",
      "\tValidation Loss: 1377540052026.2556\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 1090658129800.5425\n",
      "\tValidation Loss: 1376711749001.1938\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 1090539202864.3151\n",
      "\tValidation Loss: 1376647109632.326\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 1090496683214.1729\n",
      "\tValidation Loss: 1376793159903.6584\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 1090479965189.0006\n",
      "\tValidation Loss: 1376974799038.9314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 564906.2500,  114946.6641,  430620.7812,  429760.5000,  171411.6719,\n",
       "          54735.9023,  195709.6406,  184359.5469,  455962.8750,  204253.8750,\n",
       "         271819.3750,   79684.7891, 4755194.5000], requires_grad=True)"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0001 Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500:\n",
      "\tTraining Loss: 21016725522192.53\n",
      "\tValidation Loss: 22315362295585.32\n",
      "Epoch 1000:\n",
      "\tTraining Loss: 17149738002054.932\n",
      "\tValidation Loss: 18333443285931.68\n",
      "Epoch 1500:\n",
      "\tTraining Loss: 14083016420022.963\n",
      "\tValidation Loss: 15171013401191.445\n",
      "Epoch 2000:\n",
      "\tTraining Loss: 11634161197368.83\n",
      "\tValidation Loss: 12639516396428.236\n",
      "Epoch 2500:\n",
      "\tTraining Loss: 9667791925794.832\n",
      "\tValidation Loss: 10600009046729.742\n",
      "Epoch 3000:\n",
      "\tTraining Loss: 8081782470019.58\n",
      "\tValidation Loss: 8948300625586.043\n",
      "Epoch 3500:\n",
      "\tTraining Loss: 6798012473899.022\n",
      "\tValidation Loss: 7605048058276.607\n",
      "Epoch 4000:\n",
      "\tTraining Loss: 5755944995054.791\n",
      "\tValidation Loss: 6508957487179.275\n",
      "Epoch 4500:\n",
      "\tTraining Loss: 4908173487794.751\n",
      "\tValidation Loss: 5612108117721.291\n",
      "Epoch 5000:\n",
      "\tTraining Loss: 4217230856032.463\n",
      "\tValidation Loss: 4876643615819.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 446630.5000,  280736.6250,  337751.0625,  294763.8125,  181535.0938,\n",
       "          41578.7227,  105279.8672,  126069.5078,  356954.8438,  248250.8125,\n",
       "         219036.3438,  156873.2500, 2998292.2500], requires_grad=True)"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], 0.0001)\n",
    "training_loop(5000, optimizer, params, t_in=train_inputs, t_out=train_outputs, v_in=X_test, v_out=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models above have the following (best case) validation losses:\n",
    "- ADAM: \n",
    "    - 0.1: 27363289898558.938\n",
    "    - 0.01: 27375986157047.863\n",
    "    - 0.001: 27377256726395.24\n",
    "    - 0.0001: 27377383791266.824\n",
    "- SGD:\n",
    "    - 0.1: 1377610385759.4404\n",
    "    - 0.01: 1377610918904.6133\n",
    "    - 0.001: 1376974799038.9314\n",
    "    - 0.0001: 4876643615819.97\n",
    "\n",
    "In my previous homework the losses were close to about 1.5e13. The ADAM set has a worse loss than the original linear regression, however the SGD set has a significantly better loss of 1.3e12."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
